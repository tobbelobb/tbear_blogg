<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="blogtemplate.xsl"?>
<posts year="2021">
  <post id="hangprinter_project_70" heading="hp-mark Is Good But Lonely" date="27-3-2021">
    <p>
      The rabbit hole has gotten deeper.
      But progress is fast at this stage.<br />
      Average error (that's accuracy) has shrunk from ca 35 mm to ca 3.5 mm.
      Maybe even smaller.
      I haven't had much time to test accuracy thoroughly yet.
    </p>
    <p>
      Precision (that's stability of repeated measurements) at the origin is down from ca 5 mm to ca 1 mm.
      And also:
    </p>
    <p>
      CHECK!<input type="checkbox" checked="checked" disabled="disabled">Detect all markers on 95% of training images<br /></input>
    </p>
    <p>
      The markers have changed from small colored spheres to bigger retro-reflective disks.
      They're cheaper, lighter, easier to manufacture, and perform much, much better.
    </p>
    <p>
      I had to go and implement the disk geometric equations.
      My body protested for days when I picked up that task.
      Luckily, this time I had a research paper to guide me through most of the theory,
      and I could quickly replicate my old test structure.
      This made me ca 10x faster compared to when I did the sphere geometry.
    </p>
    <p>
      I've posted a couple of demos since last time:
    </p>
    <figure>
      <div class='embed-container'>
        <iframe src='https://www.youtube.com/embed/m9qjuZQowCE'
          frameborder='0'
          allowfullscreen='true'>
        </iframe>
      </div>
    </figure>
    <figure>
      <div class='embed-container'>
        <iframe src='https://www.youtube.com/embed/yRF-zevGHlQ'
          frameborder='0'
          allowfullscreen='true'>
        </iframe>
      </div>
    </figure>
    <p>
      The first video shows the more important use case: anchor calibration aided by hp-mark.
      It enables all other hp-mark use cases, including homing.
    </p>
    <p>
      So hp-mark is growing up.
    </p>
    <p>
      The extremely high recognition and identification rate I have now is thanks to some LEDs
      that I put around the camera:
    </p>
    <figure>
      <a href="./bilder/POWERFUL.jpeg">
        <img src="./bilder/POWERFUL_liten.jpeg" alt="My Picam with led rings around it" width="500" height="253"/>
      </a>
      <figcaption>My picam v2 with two rings of in total 20 LEDs around it.
        This removes most problems I had with shadows disturbing measurements.
        I'd say it took identification rate from ca 95% to ca 99%(?).
        Out of ca 1000 test images, I haven't recorded a single identification failure yet.
      </figcaption>
    </figure>
    <p>
      I know I could enhance accuracy and precision further by mounting these slightly higher end, low distortion lenses:
    </p>
    <figure>
      <a href="./bilder/low_distortion_lenses.jpeg">
        <img src="./bilder/low_distortion_lenses_liten.jpeg" alt="A set of low distortion lenses" width="500" height="281"/>
      </a>
      <figcaption>A set of low distortion lenses that I ordered from Arducam.
        This setup would use the same image sensor, wire connection, and software interface as the current Picam v2.</figcaption>
    </figure>
    <p>
      However, changing the camera PCB and camera lens means having to calibrate the new camera and making a new mounting bracket.
      Plus all the fiddling with wires, focusing the camera, unexpected stuff etc.
    </p>
    <p>
      My guess is 1-2 days of work.
      Is it worth it? What are my goals?
    </p>
    <h3>Keep Your Head Down And Work!</h3>
    <p>
      This sprint's goal is "high accuracy auto calibration".
      The higher level goal is "a reliable work horse".
      Peace of mind.
    </p>
    <p>
      The better camera achieves all of that.
      So I have to do it.
      Just like I redid the markers.
    </p>
    <p>
      This isn't how I worked a few years back.
      This isn't how the HP1, HP2, HP3, and first prototype of HP4 were made.
      They were all "just barely working"-systems.
      This is why HP4 will be different.
    </p>
    <h3>AAAAAAA!</h3>
    <p>
      Body is shouting loudly.
      And for good reason.
    </p>
    <p>
      Rest of World, aka everyone I meet, care extremely little about hp-mark
      in its current form.
      It you're reading this blog post, your among very few
      (<a href="https://torbjornludvigsen.goatcounter.com/">source</a>).
    </p>
    <p>
      As much as I crave attention, Rest of World craves brain tickle.
      Humans need this always.
      Brains want to light up.
    </p>
    <p>
      Current form hp-mark just isn't very...
    </p>
    <figure>
      <a href="./bilder/darth_vader_helmet.jpg">
        <img src="./bilder/darth_vader_helmet_liten.jpg" alt="A side shot of Darth Vader's helmet" width="500" height="376"/>
      </a>
      <figcaption>MRI scan of person reading up on how a measurement system that is unrelated to their life improved from 35 to 3.5.</figcaption>
    </figure>
    <p>
      ... stimulating.
      For me, a person who is constantly dying for attention, this is a problem.
    </p>

    <h3>What To Do</h3>
    <p>
      Even at nanometer precision, isolated hp-mark would be precisely one nano stimulating to the non-Hangprinter owning Rest of World.
      Common solutions to this kind of problem:
      <ol>
        <li>Pay folks to suffer thruogh your under-stimulating thing. Attention-as-a-service. Day jobs. Ads. This is the most common solution out in the wild.</li>
        <li>Find people who love your stuff by unusual amounts.</li>
        <li>Put your thing into a more exciting context/story.</li>
        <li>Pitch! Learn pitching dark arts.</li>
        <li>Accept defeat.</li>
      </ol>
    </p>
    <p>
      All of these have their own pros and cons.
      Too much to write down here.
      I will do number 5 for the rest of this sprint, and then try my luck at number 3.
    </p>
    <figure style="left-margin:auto">
      <a href="./bilder/current_sprint.JPG">
        <img src="./bilder/current_sprint_liten.JPG" alt="Tasks of the current sprint" width="338" height="600"/>
      </a>
      <figcaption>The sprint in question.</figcaption>
    </figure>
    <p>
      The first slightly more exciting context, at least for hp-mark, will be HP4.
      End-to-end, released machine, with build manual and all.
      I look forward to that.
    </p>
    <h3>Outlook</h3>
    <p>
      HP4 is not very interesting on its own either though.
      It will need it's own number 3 eventually.
      A context creates a story.
      Without a story, humans can not understand, or hardly even percieve your stuff.
    </p>
    <h3>Number 3 Suggestions for HP4</h3>
    <ul>
      <li>
        Hangprinting a body shaped house that's later sold as an art piece on a blockchain.
      </li>
      <li>
        A variable size telescope rod framed Hangprinter on wheels that collects its own raw material and can flip pancakes.
        Perfect for Burning Man.
      </li>
      <li>
        Using HP4 as a motorized trampoline for cats. Computer vision detects cat. Ejects/bounces cat. Cat happy. The end.
      </li>
      <li>
        A Hangprinter v4 built... inside Minecraft. And then being sold as an NFT on a blockchain. Just add the blockchain to the end of every suggestion from here on.
      </li>
      <li>
        A Hangprinter with AI that registers its own company, and prints and assembles an array of other machines to be its employees.
      </li>
      <li>
        A Hangprinter that just connects deeply with people.
      </li>
      <li>
        Something simpler. A HP that puts cheese on a pizza and the slices it.
      </li>
      <li>
        Hangprinter doing something oddly satesfying, like cutting paper, or 3d printing ceramic poop. With glazing.
      </li>
      <li>
        A Hangprinter hanging down from space.
      </li>
      <li>
        A Hangprinter mounted upside-down. So D-anchor is on floor, ABC-anchors in ceiling, and print surface is in the ceiling.
        Mounted sideways would also work, for hype purposes, but not very well in practice.
      </li>
      <li>
        A big Hangprinter outside using a hundred helium balloons as its D-anchor.
      </li>
      <li>
        A single, fat, vertical, constant speed extrusion. Preferrably made with the HP from space.
      </li>
      <li>
        Printing a complete working bike in one go.
      </li>
      <li>
        A flexible motor driven suspended Hang-printbed. A <a href="https://gitlab.com/tobben/hangbed">hangbed</a>.
      </li>
      <li>
        A HP that's just super huge, with ABC anchors mounted on big trucks, and D on a high crane.
        This is the most frequently encountered one out in the wild, which more or less guarantees that it's a good one.
        The word HUUUUGE by itself already tickles a bit. I'm sure you can feel it.
      </li>
    </ul>
    <h3>Short End Note</h3>
    <p>
      The old HP story is basically "a living thing that creates economic value".
      Fully automated, self-replicating, printing furniture, taking zero space when not in use.
      I'm not sure if that is tickly enough from my attention cravings' perspective.
      Before it's even out there we'll never know.
    </p>
    <p>
      hp-mark is getting quite good, but also lonely.
    </p>

  </post>
  <post id="hangprinter_project_69" heading="hp-mark Exists Now" date="15-2-2021">
    <p>
      I climbed down a rabbit hole recently.
      Nearly half a year working on hp-mark.
      The past 84 days even skipping blog post and newsletter writing.
    </p>
    <p>
      Progress has been steady.
      It works now.
      <a href="https://gitlab.com/tobben/hp-mark">hp-mark</a> measures positions, like:
    </p>
    <figure>
      <a href="./bilder/result-217_0.png">
        <img src="./bilder/result-217_0_liten.png" alt="First ever non-zero result from hp-mark" width="500" height="376"/>
      </a>
      <figcaption>Result 1: [-1.27, -217.65, 2.68]. Hand measured position is [0, -217, 0].</figcaption>
    </figure>
    <p>
      Accuracy is not fantastic.
      The image above is a lucky one, with only 3 mm of error.
      A more commonly seen error is around 35 mm.
    </p>
    <p>
      A lot of hp-mark work remains.
      I ticked 2 boxes, and added 6 new ones in the
      <a href="https://gitlab.com/tobben/hp-mark/-/blob/master/README.md#status">roadmap</a>
      today:
    </p>
    <p>
      <input type="checkbox" checked="checked" disabled="disabled">Aquire camera 6D pose (this includes defining our world coordinate system)<br /></input>
      <input type="checkbox" checked="checked" disabled="disabled">Aquire effector 6D pose<br /></input>
      <input type="checkbox" disabled="disabled">Detect all markers on 95% of training images<br /></input>
      <input type="checkbox" disabled="disabled">Take image ourselves upon request, don't rely on other programs to take image first<br /></input>
      <input type="checkbox" disabled="disabled">Create a continous stream of position measurements (video?)<br /></input>
      <input type="checkbox" disabled="disabled">Get a statistical idea about size of error<br /></input>
      <input type="checkbox" disabled="disabled">Respond to RepRapFirmware/Duet request for position measurement<br /></input>
      <input type="checkbox" disabled="disabled">Integrate a second camera, to reduce error<br /></input>
    </p>
    <p>
      I'm a bit overwhelmed still.
      I need to look backwards a bit.
    </p>
    <h3>What Have I Done?</h3>
    <p>
      I've been surprised.
    </p>
    <figure>
      <video width="500" height="367" controls="controls">
        <source src="bilder/fun.mp4" type="video/mp4"/>
         <!--source src="movie.ogg" type="video/ogg"-->
         Your browser does not support the video tag.
      </video>
      <figcaption>
        Video stitched together from todays test images.
      </figcaption>
    </figure>
    <!--figure>
      <a href="./bilder/result-217_4.png">
        <img src="./bilder/result-217_4_liten.png" alt="First ever non-zero result from hp-mark" width="500" height="376"/>
      </a>
      <figcaption>Result 3: [0.24, -220.14, 1.99]. Hand measured position is [0, -217, 0].</figcaption>
    </figure -->
    <p>
      I chose C++, OpenCV, and a very traditional approach for this project.
      I just wanted the most basic code that would mecanically find circles among pixels,
      and then apply static geometric equations to transform circles into a nozzle position.
      No AI stuff, no GPU stuff, no fancy hardware control, just
$$
  f(x) \rightarrow y,
$$
     where \(x\) is an image, and \(y\) is a nozzle position.
    </p>
    <p>
      Such an old and explored problem!
      I felt confident.
    </p>
    <p>
      Some things that took long for me to program, in descending order:
      <ul>
        <li><b>Good enough ellipse detection.</b> OpenCV's <code>SimpleBlobDetector</code> was ok, but ultimately not
          robust enough for our purposes. I was lucky to find <a href="https://github.com/CihanTopal/ED_Lib">ED_Lib</a>, and spent a little over a month integrating it into hp-mark.
          For example, I had to fight a little to get sub-pixel accuracy in the center and size data. More about that
          <a href="https://github.com/CihanTopal/ED_Lib/issues/12">here</a>.</li>
        <li><b>Geometry.</b> A photon bounces off a sphere, through a pinhole, and onto an image sensor. Many more follow.
          They create a pattern, a projection, on the image sensor.
          Given the position of the sphere, what's the equation of its projection? Or vice versa; given a projection,
          what's the position of the sphere? Which projected point correspond to the sphere's center? I derived all relevant equations by hand and wrote tests that wouldn't go
          green before I was exactly right.
          To bootstrap the chain of testable geometric functions, I derived the most basic equation in two different
          ways, and tested that the two derived functions gave exactly the same results.
          The system would never be good if the theory it rested upon wasn't sound, so I spent the time to make this
          perfect.</li>
        <li><b>Filtering among ellipses.</b> The improved ellipse detector found <i>lots</i> of ellipses.
          Getting hp-mark to determine which ellipses represent real markers, was hard.
          To  be real useful, hp-mark must be able to identify all its markers almost all the time,
          so I spent extra time here as well. I will return to this point in the future, but we're at least finding
          all the markers ca 80% of the time now.</li>
        <li><b>Color recognition.</b> The human brain is full of heuristics that helps us determine color,
          in a wide variety of situations. Very fine details of camera settings, light/shadow,
          and way of definition, throws a simplistic computer program off very easily.
          The strongest heuristic I was able to program, in which all colors are relative, still can not
          identify a non-marker in a set of six real and one false marker.
          Still, I was able to keep color as a marker categorizer that lets us
          avoid having to put QR-codes on our markers.
          I fought a bit for the aesthetics.
        </li>
      </ul>
    </p>
    <p>
      I feel like I'm almost too tired of it to even write about this stuff now.
      But before I climb out of this rabbit hole,
      I can show you something about how the ellipse detector works internally:
    </p>
    <figure>
      <a href="./bilder/input3.png">
        <img src="./bilder/input3.png" alt="Input to ellipse detector" width="500" height="407"/>
      </a>
      <figcaption>A zoomed in version of the original image from the PiCam v2.</figcaption>
    </figure>
    <figure>
      <a href="./bilder/edgeImage3.png">
        <img src="./bilder/edgeImage3.png" alt="edge image inside ellipse detector" width="500" height="407"/>
      </a>
      <figcaption>Color contrast between pixels were used to find these edges in the image.</figcaption>
    </figure>
    <figure>
      <a href="./bilder/segmentImage3.png">
        <img src="./bilder/segmentImage3.png" alt="segment image inside ellipse detector" width="500" height="407"/>
      </a>
      <figcaption>The edge pixels are the grouped into segments. Each segment has a different color in this visualization.
        A single segment that forms a closed circle or ellipse will be detected already at this stage.
        Most detectors can find complete closed-curve ellipses quickly and easily.
        What sets ED_Lib apart is how hard it tries to piece together the chopped-up circles, and how quick and cheap
        it manages to do this.
      </figcaption>
    </figure>
    <figure>
      <a href="./bilder/lines1Image3.png">
        <img src="./bilder/lines1Image3.png" alt="lines image inside ellipse detector" width="500" height="407"/>
      </a>
      <figcaption>The segments are split up further into lines and arcs. These are the lines.</figcaption>
    </figure>
    <figure>
      <a href="./bilder/edarcs1Image3.png">
        <img src="./bilder/edarcs1Image3.png" alt="arcs image inside ellipse detector" width="500" height="407"/>
      </a>
      <figcaption>... and these are the arcs.
        (If you compare very closely with the segments image, you find that not all arcs match exactly.
        They should match exactly.
        I mixed up images from two different runs when preparing this, so this arc visualization is ever so slightly off.
        It's still representative for the result below though, in that the top blue marker could not be found amog these arcs either, but all other markers were found.)
      </figcaption>
    </figure>
    <figure>
      <a href="./bilder/edCircles3.png">
        <img src="./bilder/edCircles3.png" alt="output of ellipse detector" width="500" height="407"/>
      </a>
      <figcaption>The arcs are combined into circles and ellipses according to many different heuristics.</figcaption>
    </figure>
    <p>
      In the image above, we see that one marker was missed, despise ED_Lib's many different heuristics.
      I tried to tune the heuristics for the hp-mark use case.
      See how that went, <a href="https://github.com/CihanTopal/ED_Lib/issues/13">here</a>.
    </p>
    <p>
      Ultimately failing to tune the heuristics convinced me to put background plates below my markers.
      That is what I'm currently working on.
      They will probably end up looking something like this:
    </p>
    <figure>
      <a href="./bilder/octagon.jpeg">
        <img src="./bilder/octagon_liten.jpeg" alt="marker with bent octagonal background" width="500" height="500"/>
      </a>
      <figcaption>Test of marker background with bent octagonal background.</figcaption>
    </figure>
    <p>
      The final background design will probably be flat and circular, and hp-mark will use the edge of the
      background, as well as the marker itself, to determine its position, further improving both robustness and accuracy of the system.
    </p>
    <p>
      But not today.
      I'm so tired of that kind of programming.
      Let's celebrate the restuls at the top of this post for a while first.
      And let's rest.
    </p>
  </post>
</posts>
